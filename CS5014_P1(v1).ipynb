{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a705a7",
   "metadata": {},
   "source": [
    "# CS5014 Machine Learning \n",
    "\n",
    "##### Practical 1 \n",
    "##### Credits: 50% of the coursework\n",
    "\n",
    "##### Deadline: 12/03/2025\n",
    "\n",
    "\n",
    "_Note that MMS is the definitive source for deadlines and weights._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26dde6",
   "metadata": {},
   "source": [
    "## Aims\n",
    "\n",
    "\n",
    "The objectives of this assignment are:\n",
    "\n",
    "* deepen your understanding of linear regression and logistic regression\n",
    "* gain experience in implementing learning algorithms \n",
    "* gain experience in evaluating machine learning algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662dc6a",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "\n",
    "You are **only allowed** to use the following imported packages for this practical. No off-the-shelf machine learning packages such as _scikit-learn_ are allowed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "931f3a91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T13:00:21.096457Z",
     "iopub.status.busy": "2025-02-13T13:00:21.095970Z",
     "iopub.status.idle": "2025-02-13T13:00:22.503662Z",
     "shell.execute_reply": "2025-02-13T13:00:22.502429Z",
     "shell.execute_reply.started": "2025-02-13T13:00:21.096403Z"
    }
   },
   "outputs": [],
   "source": [
    "# if you use jupyter-lab, switch to %matplotlib inline instead\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "%config Completer.use_jedi = False\n",
    "import matplotlib.pyplot as plt\n",
    "import autograd.numpy as np  # Thinly-wrapped numpy\n",
    "from autograd import grad    \n",
    "from autograd import hessian\n",
    "import autograd.numpy.linalg as linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a5d9e-e308-42c9-8dc8-d5d42c4055fa",
   "metadata": {},
   "source": [
    "The following method computes the gradient of a given function $f$ at an input location `initial`. Note that the finite difference method suffers from truncating and rounding errors and can be slow for large-scale machine learning models. It should never be directly used in a gradient descent algorithm. But it can be very useful to check your gradient derivation and implementation. You should always check your gradients before using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fedfaf21-f585-47e4-a083-df8d9bd467ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T13:00:22.505011Z",
     "iopub.status.busy": "2025-02-13T13:00:22.504671Z",
     "iopub.status.idle": "2025-02-13T13:00:22.511097Z",
     "shell.execute_reply": "2025-02-13T13:00:22.510210Z",
     "shell.execute_reply.started": "2025-02-13T13:00:22.504986Z"
    }
   },
   "outputs": [],
   "source": [
    "def finite_difference_gradient(f, initial, eps=1e-6):\n",
    "    initial = np.array(initial, dtype=float)\n",
    "    n = len(initial)\n",
    "    output = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        ei = np.zeros(n)\n",
    "        ei[i] = 1\n",
    "        ## debugging\n",
    "        print(\"initial:\", initial)\n",
    "        print(\"ei: \", ei)\n",
    "        ## / debugging\n",
    "        f1 = f(initial + eps * ei)\n",
    "        f2 = f(initial - eps * ei)\n",
    "        print(\"f1: \", f1)\n",
    "        output[i] = (f1-f2)/(2*eps)\n",
    "    output = output.reshape(n,1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd90e4f4-b17e-4081-b541-859b4fbc27ca",
   "metadata": {},
   "source": [
    "## Question 1 (Lasso regression)\n",
    "\n",
    "\n",
    "In this question, we are going to investigate Lasso regression. You are going to implement a gradient descent based learning algorithm for Lasso. Then use the implemented algorithm to find out what features are truely relevant in predicting the target. \n",
    "\n",
    "The dataset $\\{\\mathbf{x}^{(i)}, y^{(i)}\\}$ is imported below for you:\n",
    "* the input design matrix `d1X` contains ``n=200`` observations and each $\\mathbf{x}^{(i)}$ has ``m=200`` features \n",
    "* and the last column is the regression targets ${y}^{(i)}$ (and they are stored in `d1Y`)\n",
    "* among the 200 features, however, only three of them are relevant to the target $y$; and the rest 197 features are random noises\n",
    "* you may assume the bias term is zero for this question\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "742daef3-9b32-4027-801c-8786ae6e4166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T13:00:22.512017Z",
     "iopub.status.busy": "2025-02-13T13:00:22.511805Z",
     "iopub.status.idle": "2025-02-13T13:00:22.548825Z",
     "shell.execute_reply": "2025-02-13T13:00:22.547644Z",
     "shell.execute_reply.started": "2025-02-13T13:00:22.511995Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in dataset1\n",
    "dataset1_df = pd.read_csv('./datasets/dataset1.csv', header=0)\n",
    "dataset1 = np.array(dataset1_df)\n",
    "d1X, d1Y = dataset1[:, 0:200], dataset1[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e3e131-5ea6-45b7-b937-edc67a37ff7d",
   "metadata": {},
   "source": [
    "### Task 1.1\n",
    "\n",
    "\n",
    "Recall that Lasso regression's loss function is defined as  \n",
    "\n",
    "\n",
    "$$L(\\mathbf{w}) = \\frac{1}{2n} \\sum_{i=1}^n (y^{(i)} - \\mathbf{w}^{\\top}\\mathbf{x}^{(i)})^2 + \\lambda \\sum_{j=1}^m |w_j|,$$\n",
    "where $\\lambda >0$ is the penalty coefficient\n",
    "\n",
    "* give the gradient expression for $\\mathbf{w}$\n",
    "* then implement a gradient descent based algorithm to learn the parameter\n",
    "\n",
    "*Hint: To deal with sub-gradient descent properly, you may need to do the following: when the learning process is about to converge (e.g. after certain number of iterations)* \n",
    "1. *use a diminishing learning rate, e.g.* $\\gamma_t = \\frac{\\gamma}{\\sqrt{t}}$\n",
    "2. *if any weight switches signs during the learning process, set the weight to zero directly*\n",
    "3. *soft-thresholding, set a small constant e.g. $\\epsilon = 10^{-5}$, if any weight's absolute value drops below $\\epsilon$, set it to zero directly*;\n",
    "*You can do either 2 or 3 (or both).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c51f0e",
   "metadata": {},
   "source": [
    "#### Answer Task 1.1\n",
    "The gradient expression for $\\mathbf{w}$ $$\\large\n",
    "\t\\mathbf{w}_{Lasso} = (\\mathbf{X}^\\top\\mathbf{X} + n\\lambda \\mathbf{sign(w)})^{-1} \\mathbf{X}^\\top\\mathbf{y}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90a5df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a gradient descent algorithm\n",
    "#np.sign handles sign stuff\n",
    "# apparently because this is a subgradient i need to solve it in iterative approaches "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e24a212-6595-4d0b-acd0-f1d66ff4555a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:49:06.560372Z",
     "iopub.status.busy": "2025-02-10T17:49:06.559407Z",
     "iopub.status.idle": "2025-02-10T17:49:06.576490Z",
     "shell.execute_reply": "2025-02-10T17:49:06.575074Z",
     "shell.execute_reply.started": "2025-02-10T17:49:06.560323Z"
    }
   },
   "source": [
    "### Task 1.2 \n",
    "\n",
    "A special property of Lasso regression is sparsity. That means, if a proper penalty parameter is used, irrelevant input features' parameters will become zero. And this sparsity property can be used to find out which input features are important or relevant. In this task, you are going to use the algorithm implemented in Task 1.1 to investigate which three of the input dimensions are truly relevant in terms of predicting the targets $y$. \n",
    "\n",
    "* plot the full regularisation path of $\\hat{\\mathbf{w}}(\\lambda)$ for a range of penalty parameter $\\lambda$\n",
    "\n",
    "\n",
    "* use the plot to tell which features are relevant and what are their cooresponding weights?\n",
    "\n",
    "*Hint:*\n",
    "1. *To find out the relevant features, you should try different $\\lambda$s and find the whole regularisation path; $\\ln\\lambda \\in [-8:0]$ seems appropriate*;\n",
    "2. *It is a good idea to fit Lasso with $\\lambda$s in an ascending order; since we know as $\\lambda$ increases, more weight $\\hat{\\mathbf{w}}(\\lambda_t)$ will become sparse*; \n",
    "3. *Instead of initialising the weight randomly for the gradient descent, you may \"warm start\" the algorithm with the learnt parameter with a smaller $\\lambda$;*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85a88f75-d6e7-425d-8e42-dd19034e1c44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T13:00:22.549770Z",
     "iopub.status.busy": "2025-02-13T13:00:22.549560Z",
     "iopub.status.idle": "2025-02-13T13:00:22.553570Z",
     "shell.execute_reply": "2025-02-13T13:00:22.552783Z",
     "shell.execute_reply.started": "2025-02-13T13:00:22.549748Z"
    }
   },
   "outputs": [],
   "source": [
    "### report your results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211324e",
   "metadata": {},
   "source": [
    "## Question 2 (Logistic regression)\n",
    "\n",
    "In this question, we are going to implement a logistic regression model to do binary classification on a simulated dataset. The dataset's input feature are four-dimensional vectors $\\mathbf{x}^{(i)} \\in \\mathbb{R}^4$ and as expected the targets are binary, *i.e.* $y^{(i)} \\in \\{0, 1\\}$. \n",
    "\n",
    "\n",
    "The dataset $\\{\\mathbf{x}^{(i)}, y^{(i)}\\}$ is imported below for you:\n",
    "* ``dataset2``: 2000 observations and each input $\\mathbf{x}$ has 4 features \n",
    "* and the last column is the target ${y}^{(i)}$\n",
    "* the dataset is then split into training and testing parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34706afa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T13:00:22.554494Z",
     "iopub.status.busy": "2025-02-13T13:00:22.554288Z",
     "iopub.status.idle": "2025-02-13T13:00:22.576513Z",
     "shell.execute_reply": "2025-02-13T13:00:22.575547Z",
     "shell.execute_reply.started": "2025-02-13T13:00:22.554472Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in dataset2\n",
    "dataset2_df = pd.read_csv('./datasets/dataset2.csv', header=0)\n",
    "dataset2 = np.array(dataset2_df)\n",
    "d2X, d2Y = dataset2[:, 0:4], dataset2[:, -1]\n",
    "# split the data into training and testing \n",
    "# the training dataset has the first 1500 observation; \n",
    "# in practice, you should randomly shuffle before the split\n",
    "d2_xtrain, d2_ytrain = d2X[0:1500, :], d2Y[0:1500]\n",
    "# the testing dataset has the last 500\n",
    "d2_xtest, d2_ytest = d2X[1500:, :], d2Y[1500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9270ebbf",
   "metadata": {},
   "source": [
    "### Task 2.1 Implementation of logistic regression\n",
    "\n",
    "Your task here is to implement a gradient descent based algorithm to train a logistic regression model. For this task, you cannot use `autograd`'s auto-differentiation method (*i.e.* the imported `grad` method). You will be guided to finish the task step by step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c28469",
   "metadata": {},
   "source": [
    "First, implement the `sigmoid` function:\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1+e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8746cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2670fb",
   "metadata": {},
   "source": [
    "Second, implement the cross-entropy loss and its gradient. You may want to refer to the lecture slides for the details. Recall the binary **C**ross **E**ntropy (CE) _loss_ is \n",
    "\n",
    "\n",
    "$$\n",
    "L(\\mathbf{w}, b)=  -\\frac{1}{n}\\sum_{i=1}^n {y^{(i)}} \\ln \\sigma^{(i)}+ (1- y^{(i)}) \\ln (1-\\sigma^{(i)})\n",
    "$$\n",
    "\n",
    "where $\\sigma^{(i)} =\\sigma(\\mathbf{w}^\\top\\mathbf{x}^{(i)} + b).$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcf4a31",
   "metadata": {},
   "source": [
    "### 2.1 Answer. \n",
    "The loss in matrix form is  $$J(\\mathbf{y}, \\hat{\\mathbf{y}}) = -\\frac{1}{n}\\left[\\,\\mathbf{y}^{T}\\ln(\\sigma) + (\\mathbf{1}-\\mathbf{y})^{T}\\ln(\\mathbf{1}-\\sigma)\\,\\right]$$\n",
    "\n",
    "The gradient with respect to w for cross entropy loss is $$\\large\n",
    "\\nabla \\ell(\\mathbf{w}) =-\\frac{1}{n} \\mathbf{X}^\\top (\\mathbf{y} - \\boldsymbol{\\sigma})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8912594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss_with_gradient(w, b, X, y):\n",
    "    '''\n",
    "    y -> n x 1\n",
    "    x -> n x m \n",
    "    w -> m x 1\n",
    "    b -> float\n",
    "    Output: \n",
    "    loss = float\n",
    "    gradient_w -> m x 1\n",
    "    gradient_b -> m x 1\n",
    "    '''\n",
    "    # Number of samples\n",
    "    #n = X.size\n",
    "    n = float(X.shape[0])\n",
    "    # Compute prediction w sigmoid function \n",
    "    temp = np.dot(X, w) + b\n",
    "    sigma = sigmoid(temp)\n",
    "\n",
    "    # Debug a little\n",
    "    # print(\"w shape: \", w.shape)\n",
    "    # print(\"X shape: \" , X.shape)\n",
    "    # print(\"y shape: \", y.shape)\n",
    "    # print(\"sigma shape: \" , sigma.shape)\n",
    "    ## compute the loss \n",
    "    #error = y.T @ np.log(sigma) + (1-y).T @ np.log(1 - sigma)\n",
    "    error = - y.T @ np.log(sigma) - (1-y.T) @ np.log(1 - sigma)\n",
    "    loss = (np.sum(error)) / n\n",
    "\t## compute the gradient w.r.t w and b\n",
    "    #gradient_w = - (1/n) * (X.T @ (y - sigma))\n",
    "    gradient_w = -  (1/n) * np.dot(X.T , (y - sigma)) \n",
    "    gradient_b = - (1/n) * np.sum(y - sigma)\n",
    "    # print(\"Gradient shape: \", gradient.shape)\n",
    "\t## return the loss and the required gradients\n",
    "    return loss, gradient_w, gradient_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "753531fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss: 0.36686678640551745\n",
      "[-0.20687020897043107, -0.14394676417074018]\n",
      "-0.036199749142716765\n"
     ]
    }
   ],
   "source": [
    "# TODO get rid of this - testing cross_entropy_loss_with_gradient()\n",
    "# Test parameters\n",
    "# w = np.array([[0.5], [-0.5]])  \n",
    "# b = 1          \n",
    "# X = np.array([[1.0, -1.0],\n",
    "#               [0.5,  0.0],\n",
    "#               [0.5,  1.5]]) \n",
    "# y = np.array([[1], [0], [1]])  \n",
    "\n",
    "X = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])  \n",
    "y = np.array([0, 0, 0, 1, 1, 1])  \n",
    "w = np.array([1,1])\n",
    "b = -3    \n",
    "\n",
    "\n",
    "\n",
    "# Test your function\n",
    "loss_test, grad_w_test, grad_b_test = cross_entropy_loss_with_gradient(w, b, X, y)\n",
    "\n",
    "print(\"Cross Entropy Loss:\", loss_test)\n",
    "print(grad_w_test.tolist())\n",
    "print(grad_b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6ace99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the gradient implementation using the finite diff method provided\n",
    "\n",
    "# # first test the sigmoid function\n",
    "# # Generate an array of evenly spaced values between -10 and 10\n",
    "# z_tmp = np.arange(-10,11)\n",
    "\n",
    "# # Use the function implemented above to get the sigmoid values\n",
    "# sig = sigmoid(z_tmp)\n",
    "\n",
    "# # Code for pretty printing the two arrays next to each other\n",
    "# np.set_printoptions(precision=3) \n",
    "# print(\"Input (z), Output (sigmoid(z))\")\n",
    "# print(np.c_[z_tmp, sig])\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Plot z vs sigmoid(z)\n",
    "# fig,ax = plt.subplots(1,1,figsize=(5,3))\n",
    "# ax.plot(z_tmp, sig, c=\"b\")\n",
    "\n",
    "# ax.set_title(\"Sigmoid function\")\n",
    "# ax.set_ylabel('sigmoid(z)')\n",
    "# ax.set_xlabel('z')\n",
    "# #draw_vthresh(ax,0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2a25c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.498333393278696, 0.4988394298399669]\n",
      "0.49861806546328574\n"
     ]
    }
   ],
   "source": [
    "# Testing gradient at a location\n",
    "X_tmp = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])\n",
    "y_tmp = np.array([0, 0, 0, 1, 1, 1])\n",
    "w_tmp = np.array([2.,3.])\n",
    "b_tmp = 1.\n",
    "loss, grad_w_test, grad_b_test = cross_entropy_loss_with_gradient(w=w_tmp, b=b_tmp, X=X_tmp, y=y_tmp)\n",
    "# print(f\"dj_db: {dj_db_tmp}\" )\n",
    "# print(f\"dj_dw: {dj_dw_tmp.tolist()}\" )\n",
    "print(grad_w_test.tolist())\n",
    "print(grad_b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "92b87616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial: [2.5 2.  1.5 4.5 7.  6.5]\n",
      "ei:  [1. 0. 0. 0. 0. 0.]\n",
      "f1:  [0.924 0.881 0.818 0.989 0.999 0.998]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Test the gradient\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Setting function to be logistic regression model with sigmoid function \u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m fdg \u001b[39m=\u001b[39m finite_difference_gradient(sigmoid, initial\u001b[39m=\u001b[39;49m(np\u001b[39m.\u001b[39;49mdot(X_tmp, w_tmp) \u001b[39m+\u001b[39;49m b))\n",
      "Cell \u001b[0;32mIn[17], line 15\u001b[0m, in \u001b[0;36mfinite_difference_gradient\u001b[0;34m(f, initial, eps)\u001b[0m\n\u001b[1;32m     13\u001b[0m     f2 \u001b[39m=\u001b[39m f(initial \u001b[39m-\u001b[39m eps \u001b[39m*\u001b[39m ei)\n\u001b[1;32m     14\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mf1: \u001b[39m\u001b[39m\"\u001b[39m, f1)\n\u001b[0;32m---> 15\u001b[0m     output[i] \u001b[39m=\u001b[39m (f1\u001b[39m-\u001b[39mf2)\u001b[39m/\u001b[39m(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39meps)\n\u001b[1;32m     16\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mreshape(n,\u001b[39m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# Test the gradient\n",
    "# Setting function to be logistic regression model with sigmoid function \n",
    "\n",
    "fdg = finite_difference_gradient(sigmoid, initial=(np.dot(X_tmp, w_tmp) + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eafe409",
   "metadata": {},
   "source": [
    "Now, implement the gradient descent algorithm below. Before that, you should consider testing our gradient implementation before using it in the training algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c8f29df4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T13:00:22.608085Z",
     "iopub.status.busy": "2025-02-13T13:00:22.607861Z",
     "iopub.status.idle": "2025-02-13T13:00:22.624092Z",
     "shell.execute_reply": "2025-02-13T13:00:22.623063Z",
     "shell.execute_reply.started": "2025-02-13T13:00:22.608061Z"
    }
   },
   "outputs": [],
   "source": [
    "def logistic_regression_train(X, y, lr, tol= 1e-5, maxIters= 2000):\n",
    "    ''' \n",
    "    X -> n x m  \n",
    "    y -> n x 1\n",
    "    lr -> learning rate (scalar)\n",
    "    tol -> tolerance (scalar)\n",
    "    maxIters -> max number of iterations/epochs (scalar)\n",
    "\n",
    "    OUTPUT: \n",
    "    w0 -> m x 1\n",
    "    b0 -> scalar\n",
    "    losses -> maxiters x 1 array                # TODO confirm this \n",
    "\n",
    "    '''\n",
    "\n",
    "    n, d = X.shape \n",
    "    # initialise w0, b0\n",
    "    w0 = np.zeros(d)    #TODO \n",
    "    b0 = 0.0            #TODO\n",
    "    losses = []\n",
    "    # loop until converge\n",
    "    for i in range(maxIters):\n",
    "        loss, grad_w, grad_b = cross_entropy_loss_with_gradient(w0, b0, X, y)\n",
    "        ## Implement gradient descent here\n",
    "        w0 = w0 - lr * grad_w\n",
    "        b0 = b0 - lr * grad_b\n",
    "        # Store loss \n",
    "        losses.append(loss)\n",
    "        # Check convergence here \n",
    "        # if True:\n",
    "        #    break\n",
    "    return w0, b0, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4e01f5",
   "metadata": {},
   "source": [
    "After you finish implementing all the above methods, use your learning algorithm to train a logistic regression model on the training dataset and answer the following questions:\n",
    "\n",
    "* plot the learning curve\n",
    "* report the learnt parameter with a learning rate 0.1, `tol=1e-5` and `maxIters=2000`\n",
    "* report the classification accuracy on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "22a1c3bd-ce1c-4121-a606-523ef126e9dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T13:00:22.625404Z",
     "iopub.status.busy": "2025-02-13T13:00:22.625164Z",
     "iopub.status.idle": "2025-02-13T13:00:22.640723Z",
     "shell.execute_reply": "2025-02-13T13:00:22.639423Z",
     "shell.execute_reply.started": "2025-02-13T13:00:22.625378Z"
    }
   },
   "outputs": [],
   "source": [
    "## run your algorithm and report your findings\n",
    "d2_w0, d2_b0, d2_losses  = logistic_regression_train(d2_xtrain, d2_ytrain, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "63f4b318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.6931471805599446), np.float64(0.6848363752017564), np.float64(0.6768598862324956), np.float64(0.6692020943076912), np.float64(0.6618480350670347), np.float64(0.6547833882606605), np.float64(0.6479944644306485), np.float64(0.6414681895981891), np.float64(0.6351920883586804), np.float64(0.6291542657412851), np.float64(0.6233433881466285), np.float64(0.617748663636565), np.float64(0.6123598218134466), np.float64(0.607167093493062), np.float64(0.6021611903453409), np.float64(0.5973332846499079), np.float64(0.5926749892894597), np.float64(0.5881783380825395), np.float64(0.583835766538429), np.float64(0.5796400931003063), np.float64(0.5755845009283886), np.float64(0.5716625202622558), np.float64(0.5678680113907373), np.float64(0.5641951482485053), np.float64(0.5606384026506261), np.float64(0.5571925291696685), np.float64(0.5538525506543812), np.float64(0.5506137443843224), np.float64(0.5474716288510126), np.float64(0.5444219511530962), np.float64(0.5414606749905388), np.float64(0.5385839692409646), np.float64(0.5357881970997814), np.float64(0.5330699057646798), np.float64(0.5304258166443686), np.float64(0.5278528160709682), np.float64(0.5253479464952826), np.float64(0.5229083981441709), np.float64(0.5205315011193913), np.float64(0.5182147179176007), np.float64(0.5159556363515789), np.float64(0.5137519628532492), np.float64(0.5116015161396101), np.float64(0.5095022212233073), np.float64(0.5074521037502081), np.float64(0.5054492846470088), np.float64(0.5034919750625861), np.float64(0.5015784715874867), np.float64(0.49970715173663754), np.float64(0.4978764696810396), np.float64(0.49608495221487253), np.float64(0.4943311949451017), np.float64(0.4926138586913092), np.float64(0.4909316660840979), np.float64(0.48928339835100876), np.float64(0.4876678922794793), np.float64(0.4860840373469179), np.float64(0.48453077300850295), np.float64(0.48300708613382926), np.float64(0.48151200858400717), np.float64(0.48004461492127826), np.float64(0.4786040202436677), np.float64(0.47718937813759477), np.float64(0.47579987874177176), np.float64(0.4744347469161036), np.float64(0.47309324050963847), np.float64(0.47177464872198727), np.float64(0.47047829055292234), np.float64(0.4692035133351853), np.float64(0.4679496913458193), np.float64(0.46671622449159894), np.float64(0.46550253706440153), np.float64(0.4643080765625932), np.float64(0.46313231257473286), np.float64(0.4619747357221125), np.float64(0.46083485665685203), np.float64(0.45971220511245414), np.float64(0.45860632900391), np.float64(0.4575167935746052), np.float64(0.4564431805874448), np.float64(0.45538508755775364), np.float64(0.4543421270256593), np.float64(0.45331392586578945), np.float64(0.4523001246322405), np.float64(0.45130037693689884), np.float64(0.45031434885929456), np.float64(0.44934171838627934), np.float64(0.4483821748799161), np.float64(0.44743541857205615), np.float64(0.44650116008417134), np.float64(0.44557911997108535), np.float64(0.4446690282873277), np.float64(0.4437706241749029), np.float64(0.4428836554713403), np.float64(0.44200787833694766), np.float64(0.4411430569002544), np.float64(0.44028896292068953), np.float64(0.43944537546758866), np.float64(0.43861208061467427), np.float64(0.43778887114920645), np.float64(0.43697554629503704), np.float64(0.43617191144885253), np.float64(0.43537777792891774), np.float64(0.434592962735685), np.float64(0.43381728832365235), np.float64(0.43305058238390165), np.float64(0.43229267763676793), np.float64(0.4315434116341295), np.float64(0.4308026265708267), np.float64(0.4300701691047539), np.float64(0.4293458901851843), np.float64(0.4286296448889181), np.float64(0.4279212922638597), np.float64(0.4272206951796582), np.float64(0.4265277201850561), np.float64(0.4258422373716191), np.float64(0.42516412024352773), np.float64(0.42449324559313784), np.float64(0.42382949338202247), np.float64(0.4231727466272319), np.float64(0.4225228912925167), np.float64(0.4218798161842714), np.float64(0.4212434128519738), np.float64(0.4206135754929028), np.float64(0.41999020086092637), np.float64(0.41937318817917085), np.float64(0.41876243905638255), np.float64(0.41815785740680617), np.float64(0.4175593493734177), np.float64(0.41696682325434997), np.float64(0.4163801894323615), np.float64(0.4157993603072088), np.float64(0.41522425023078396), np.float64(0.41465477544489004), np.float64(0.4140908540215341), np.float64(0.4135324058056187), np.float64(0.41297935235992267), np.float64(0.4124316169122696), np.float64(0.41188912430477953), np.float64(0.4113518009451124), np.float64(0.41081957475961295), np.float64(0.41029237514826994), np.float64(0.40977013294140896), np.float64(0.40925278035804435), np.float64(0.4087402509658092), np.float64(0.4082324796424033), np.float64(0.4077294025384819), np.float64(0.4072309570419312), np.float64(0.40673708174346135), np.float64(0.40624771640346763), np.float64(0.4057628019200985), np.float64(0.40528228029848135), np.float64(0.40480609462105605), np.float64(0.4043341890189672), np.float64(0.40386650864447377), np.float64(0.4034029996443266), np.float64(0.4029436091340799), np.float64(0.4024882851732929), np.float64(0.4020369767415852), np.float64(0.4015896337155118), np.float64(0.40114620684622254), np.float64(0.400706647737873), np.float64(0.4002709088267586), np.float64(0.39983894336113895), np.float64(0.39941070538172674), np.float64(0.39898614970281504), np.float64(0.3985652318940134), np.float64(0.398147908262573), np.float64(0.3977341358362745), np.float64(0.3973238723468579), np.float64(0.39691707621397154), np.float64(0.39651370652962153), np.float64(0.3961137230431006), np.float64(0.39571708614637935), np.float64(0.395323756859941), np.float64(0.39493369681904233), np.float64(0.39454686826038715), np.float64(0.39416323400919223), np.float64(0.3937827574666356), np.float64(0.3934054025976696), np.float64(0.39303113391918737), np.float64(0.39265991648852727), np.float64(0.392291715892306), np.float64(0.391926498235565), np.float64(0.39156423013122243), np.float64(0.39120487868981546), np.float64(0.39084841150952676), np.float64(0.39049479666648207), np.float64(0.3901440027053112), np.float64(0.3897959986299607), np.float64(0.3894507538947536), np.float64(0.3891082383956823), np.float64(0.3887684224619317), np.float64(0.388431276847622), np.float64(0.38809677272376286), np.float64(0.38776488167041484), np.float64(0.38743557566904807), np.float64(0.38710882709509437), np.float64(0.3867846087106835), np.float64(0.38646289365756087), np.float64(0.38614365545017715), np.float64(0.38582686796894755), np.float64(0.3855125054536731), np.float64(0.38520054249712), np.float64(0.3848909540387516), np.float64(0.38458371535860775), np.float64(0.38427880207132764), np.float64(0.38397619012031237), np.float64(0.3836758557720201), np.float64(0.3833777756103949), np.float64(0.3830819265314174), np.float64(0.3827882857377843), np.float64(0.3824968307337005), np.float64(0.3822075393197923), np.float64(0.38192038958812946), np.float64(0.38163535991735775), np.float64(0.3813524289679364), np.float64(0.38107157567747874), np.float64(0.38079277925619365), np.float64(0.3805160191824213), np.float64(0.3802412751982669), np.float64(0.37996852730532266), np.float64(0.37969775576048187), np.float64(0.37942894107183744), np.float64(0.3791620639946658), np.float64(0.3788971055274937), np.float64(0.37863404690824237), np.float64(0.3783728696104528), np.float64(0.3781135553395847), np.float64(0.3778560860293886), np.float64(0.37760044383835173), np.float64(0.3773466111462132), np.float64(0.3770945705505461), np.float64(0.3768443048634086), np.float64(0.3765957971080564), np.float64(0.37634903051572216), np.float64(0.37610398852245364), np.float64(0.3758606547660127), np.float64(0.37561901308283463), np.float64(0.3753790475050414), np.float64(0.3751407422575141), np.float64(0.3749040817550169), np.float64(0.37466905059937683), np.float64(0.3744356335767129), np.float64(0.3742038156547189), np.float64(0.3739735819799921), np.float64(0.37374491787541425), np.float64(0.3735178088375763), np.float64(0.3732922405342516), np.float64(0.3730681988019137), np.float64(0.3728456696432974), np.float64(0.3726246392250043), np.float64(0.37240509387514914), np.float64(0.37218702008104887), np.float64(0.37197040448694996), np.float64(0.3717552338917986), np.float64(0.3715414952470447), np.float64(0.3713291756544885), np.float64(0.3711182623641607), np.float64(0.3709087427722399), np.float64(0.37070060441900704), np.float64(0.37049383498683086), np.float64(0.37028842229819103), np.float64(0.37008435431373227), np.float64(0.3698816191303512), np.float64(0.3696802049793171), np.float64(0.36948010022442), np.float64(0.36928129336015353), np.float64(0.3690837730099252), np.float64(0.3688875279242963), np.float64(0.3686925469792515), np.float64(0.3684988191744959), np.float64(0.36830633363178034), np.float64(0.3681150795932526), np.float64(0.36792504641983675), np.float64(0.3677362235896374), np.float64(0.3675486006963697), np.float64(0.3673621674478156), np.float64(0.36717691366430205), np.float64(0.36699282927720633), np.float64(0.366809904327483), np.float64(0.36662812896421443), np.float64(0.3664474934431849), np.float64(0.3662679881254758), np.float64(0.3660896034760833), np.float64(0.3659123300625588), np.float64(0.36573615855366803), np.float64(0.36556107971807233), np.float64(0.36538708442303053), np.float64(0.3652141636331199), np.float64(0.3650423084089772), np.float64(0.36487150990605893), np.float64(0.36470175937342075), np.float64(0.36453304815251447), np.float64(0.3643653676760045), np.float64(0.36419870946660143), np.float64(0.3640330651359136), np.float64(0.3638684263833152), np.float64(0.36370478499483244), np.float64(0.36354213284204573), np.float64(0.36338046188100787), np.float64(0.36321976415117946), np.float64(0.3630600317743788), np.float64(0.3629012569537481), np.float64(0.3627434319727354), np.float64(0.36258654919409), np.float64(0.3624306010588742), np.float64(0.3622755800854881), np.float64(0.3621214788687105), np.float64(0.36196829007875175), np.float64(0.3618160064603218), np.float64(0.3616646208317113), np.float64(0.36151412608388517), np.float64(0.3613645151795918), np.float64(0.3612157811524814), np.float64(0.36106791710624064), np.float64(0.3609209162137369), np.float64(0.36077477171617656), np.float64(0.3606294769222746), np.float64(0.36048502520743575), np.float64(0.360341410012948), np.float64(0.36019862484518733), np.float64(0.36005666327483277), np.float64(0.35991551893609386), np.float64(0.3597751855259488), np.float64(0.35963565680339216), np.float64(0.35949692658869437), np.float64(0.3593589887626713), np.float64(0.35922183726596335), np.float64(0.3590854660983255), np.float64(0.35894986931792694), np.float64(0.3588150410406601), np.float64(0.3586809754394593), np.float64(0.35854766674362964), np.float64(0.35841510923818387), np.float64(0.35828329726318925), np.float64(0.3581522252131229), np.float64(0.3580218875362372), np.float64(0.3578922787339314), np.float64(0.35776339336013446), np.float64(0.3576352260206947), np.float64(0.35750777137277834), np.float64(0.35738102412427597), np.float64(0.357254979033217), np.float64(0.3571296309071925), np.float64(0.35700497460278513), np.float64(0.3568810050250075), np.float64(0.35675771712674753), np.float64(0.35663510590822073), np.float64(0.3565131664164319), np.float64(0.3563918937446412), np.float64(0.3562712830318396), np.float64(0.35615132946222966), np.float64(0.3560320282647152), np.float64(0.35591337471239526), np.float64(0.3557953641220665), np.float64(0.35567799185373195), np.float64(0.35556125331011573), np.float64(0.35544514393618404), np.float64(0.3553296592186734), np.float64(0.355214794685624), np.float64(0.3551005459059198), np.float64(0.3549869084888345), np.float64(0.3548738780835835), np.float64(0.3547614503788806), np.float64(0.3546496211025028), np.float64(0.35453838602085813), np.float64(0.3544277409385614), np.float64(0.35431768169801336), np.float64(0.3542082041789864), np.float64(0.3540993042982159), np.float64(0.3539909780089962), np.float64(0.35388322130078115), np.float64(0.3537760301987911), np.float64(0.353669400763625), np.float64(0.3535633290908753), np.float64(0.3534578113107497), np.float64(0.3533528435876981), np.float64(0.353248422120042), np.float64(0.3531445431396109), np.float64(0.35304120291138225), np.float64(0.3529383977331254), np.float64(0.35283612393505154), np.float64(0.3527343778794664), np.float64(0.352633155960429), np.float64(0.35253245460341215), np.float64(0.3524322702649708), np.float64(0.35233259943241113), np.float64(0.3522334386234654), np.float64(0.35213478438597084), np.float64(0.3520366332975518), np.float64(0.3519389819653071), np.float64(0.3518418270254995), np.float64(0.35174516514325055), np.float64(0.35164899301223834), np.float64(0.3515533073543994), np.float64(0.3514581049196337), np.float64(0.3513633824855143), np.float64(0.35126913685699884), np.float64(0.35117536486614687), np.float64(0.3510820633718383), np.float64(0.35098922925949666), np.float64(0.35089685944081594), np.float64(0.3508049508534893), np.float64(0.35071350046094196), np.float64(0.3506225052520688), np.float64(0.3505319622409713), np.float64(0.3504418684667021), np.float64(0.35035222099300894), np.float64(0.35026301690808453), np.float64(0.3501742533243172), np.float64(0.3500859273780453), np.float64(0.34999803622931586), np.float64(0.3499105770616439), np.float64(0.3498235470817759), np.float64(0.34973694351945583), np.float64(0.3496507636271944), np.float64(0.34956500468003987), np.float64(0.34947966397535263), np.float64(0.3493947388325823), np.float64(0.34931022659304706), np.float64(0.3492261246197155), np.float64(0.3491424302969918), np.float64(0.34905914103050256), np.float64(0.3489762542468865), np.float64(0.3488937673935868), np.float64(0.34881167793864565), np.float64(0.3487299833705008), np.float64(0.34864868119778536), np.float64(0.3485677689491292), np.float64(0.3484872441729628), np.float64(0.3484071044373234), np.float64(0.348327347329664), np.float64(0.34824797045666295), np.float64(0.34816897144403797), np.float64(0.3480903479363599), np.float64(0.34801209759687085), np.float64(0.34793421810730235), np.float64(0.3478567071676978), np.float64(0.34777956249623426), np.float64(0.3477027818290491), np.float64(0.3476263629200665), np.float64(0.34755030354082683), np.float64(0.3474746014803176), np.float64(0.34739925454480725), np.float64(0.3473242605576791), np.float64(0.3472496173592691), np.float64(0.3471753228067036), np.float64(0.3471013747737404), np.float64(0.3470277711506111), np.float64(0.34695450984386433), np.float64(0.3468815887762124), np.float64(0.3468090058863782), np.float64(0.34673675912894447), np.float64(0.34666484647420504), np.float64(0.3465932659080166), np.float64(0.34652201543165334), np.float64(0.34645109306166294), np.float64(0.346380496829723), np.float64(0.34631022478250134), np.float64(0.34624027498151494), np.float64(0.3461706455029927), np.float64(0.34610133443773944), np.float64(0.34603233989099963), np.float64(0.3459636599823255), np.float64(0.34589529284544324), np.float64(0.34582723662812387), np.float64(0.34575948949205343), np.float64(0.3456920496127045), np.float64(0.3456249151792114), np.float64(0.34555808439424346), np.float64(0.3454915554738827), np.float64(0.34542532664750053), np.float64(0.3453593961576369), np.float64(0.3452937622598815), np.float64(0.3452284232227535), np.float64(0.34516337732758634), np.float64(0.3450986228684106), np.float64(0.34503415815183924), np.float64(0.3449699814969553), np.float64(0.3449060912351979), np.float64(0.34484248571025317), np.float64(0.3447791632779428), np.float64(0.34471612230611587), np.float64(0.34465336117454154), np.float64(0.3445908782748023), np.float64(0.34452867201018866), np.float64(0.34446674079559547), np.float64(0.3444050830574182), np.float64(0.34434369723345093), np.float64(0.3442825817727862), np.float64(0.34422173513571397), np.float64(0.3441611557936239), np.float64(0.3441008422289065), np.float64(0.34404079293485756), np.float64(0.3439810064155811), np.float64(0.34392148118589544), np.float64(0.3438622157712389), np.float64(0.3438032087075773), np.float64(0.34374445854131214), np.float64(0.34368596382918903), np.float64(0.34362772313820883), np.float64(0.34356973504553723), np.float64(0.34351199813841793), np.float64(0.34345451101408436), np.float64(0.34339727227967387), np.float64(0.34334028055214205), np.float64(0.34328353445817844), np.float64(0.34322703263412224), np.float64(0.34317077372588006), np.float64(0.3431147563888433), np.float64(0.3430589792878077), np.float64(0.3430034410968918), np.float64(0.342948140499459), np.float64(0.3428930761880366), np.float64(0.3428382468642401), np.float64(0.34278365123869464), np.float64(0.342729288030959), np.float64(0.34267515596944964), np.float64(0.34262125379136643), np.float64(0.3425675802426177), np.float64(0.3425141340777479), np.float64(0.3424609140598638), np.float64(0.342407918960563), np.float64(0.34235514755986346), np.float64(0.34230259864613155), np.float64(0.3422502710160132), np.float64(0.3421981634743649), np.float64(0.3421462748341844), np.float64(0.34209460391654367), np.float64(0.3420431495505217), np.float64(0.3419919105731376), np.float64(0.34194088582928545), np.float64(0.3418900741716684), np.float64(0.3418394744607351), np.float64(0.34178908556461524), np.float64(0.3417389063590561), np.float64(0.3416889357273605), np.float64(0.34163917256032406), np.float64(0.34158961575617486), np.float64(0.3415402642205112), np.float64(0.3414911168662426), np.float64(0.34144217261352944), np.float64(0.3413934303897244), np.float64(0.34134488912931327), np.float64(0.3412965477738575), np.float64(0.34124840527193656), np.float64(0.34120046057909176), np.float64(0.34115271265776886), np.float64(0.341105160477263), np.float64(0.3410578030136636), np.float64(0.34101063924979946), np.float64(0.34096366817518425), np.float64(0.3409168887859635), np.float64(0.3408703000848609), np.float64(0.340823901081126), np.float64(0.340777690790482), np.float64(0.34073166823507406), np.float64(0.340685832443418), np.float64(0.34064018245034994), np.float64(0.34059471729697594), np.float64(0.34054943603062215), np.float64(0.3405043377047856), np.float64(0.34045942137908547), np.float64(0.340414686119215), np.float64(0.34037013099689306), np.float64(0.34032575508981694), np.float64(0.3402815574816158), np.float64(0.34023753726180345), np.float64(0.34019369352573214), np.float64(0.3401500253745476), np.float64(0.34010653191514345), np.float64(0.340063212260116), np.float64(0.3400200655277201), np.float64(0.33997709084182504), np.float64(0.3399342873318711), np.float64(0.3398916541328258), np.float64(0.3398491903851419), np.float64(0.33980689523471425), np.float64(0.33976476783283804), np.float64(0.33972280733616717), np.float64(0.33968101290667263), np.float64(0.33963938371160246), np.float64(0.33959791892343966), np.float64(0.3395566177198641), np.float64(0.3395154792837105), np.float64(0.33947450280293123), np.float64(0.3394336874705552), np.float64(0.3393930324846502), np.float64(0.33935253704828505), np.float64(0.33931220036948995), np.float64(0.3392720216612203), np.float64(0.3392320001413186), np.float64(0.3391921350324776), np.float64(0.33915242556220393), np.float64(0.3391128709627807), np.float64(0.3390734704712331), np.float64(0.3390342233292913), np.float64(0.3389951287833559), np.float64(0.3389561860844624), np.float64(0.3389173944882462), np.float64(0.3388787532549093), np.float64(0.33884026164918496), np.float64(0.33880191894030404), np.float64(0.3387637244019625), np.float64(0.3387256773122865), np.float64(0.3386877769538007), np.float64(0.3386500226133954), np.float64(0.3386124135822935), np.float64(0.3385749491560195), np.float64(0.33853762863436654), np.float64(0.3385004513213653), np.float64(0.3384634165252537), np.float64(0.3384265235584441), np.float64(0.3383897717374941), np.float64(0.33835316038307534), np.float64(0.33831668881994376), np.float64(0.3382803563769092), np.float64(0.3382441623868061), np.float64(0.3382081061864641), np.float64(0.33817218711667857), np.float64(0.33813640452218235), np.float64(0.33810075775161613), np.float64(0.338065246157501), np.float64(0.33802986909621), np.float64(0.33799462592793983), np.float64(0.3379595160166837), np.float64(0.3379245387302035), np.float64(0.3378896934400031), np.float64(0.3378549795213004), np.float64(0.33782039635300204), np.float64(0.3377859433176759), np.float64(0.3377516198015244), np.float64(0.33771742519435966), np.float64(0.33768335888957723), np.float64(0.33764942028412975), np.float64(0.3376156087785024), np.float64(0.3375819237766874), np.float64(0.33754836468615895), np.float64(0.3375149309178489), np.float64(0.3374816218861214), np.float64(0.33744843700874927), np.float64(0.33741537570688956), np.float64(0.33738243740505974), np.float64(0.3373496215311137), np.float64(0.33731692751621845), np.float64(0.3372843547948309), np.float64(0.3372519028046741), np.float64(0.3372195709867151), np.float64(0.33718735878514144), np.float64(0.33715526564733933), np.float64(0.33712329102387045), np.float64(0.3370914343684503), np.float64(0.337059695137926), np.float64(0.3370280727922546), np.float64(0.33699656679448103), np.float64(0.33696517661071707), np.float64(0.33693390171011983), np.float64(0.3369027415648708), np.float64(0.33687169565015435), np.float64(0.33684076344413794), np.float64(0.3368099444279503), np.float64(0.3367792380856621), np.float64(0.33674864390426495), np.float64(0.3367181613736515), np.float64(0.33668778998659576), np.float64(0.3366575292387329), np.float64(0.3366273786285397), np.float64(0.33659733765731525), np.float64(0.3365674058291618), np.float64(0.33653758265096534), np.float64(0.33650786763237645), np.float64(0.33647826028579175), np.float64(0.3364487601263354), np.float64(0.3364193666718398), np.float64(0.33639007944282845), np.float64(0.3363608979624961), np.float64(0.336331821756692), np.float64(0.33630285035390134), np.float64(0.33627398328522795), np.float64(0.3362452200843756), np.float64(0.3362165602876316), np.float64(0.33618800343384875), np.float64(0.33615954906442863), np.float64(0.33613119672330366), np.float64(0.33610294595692114), np.float64(0.3360747963142254), np.float64(0.336046747346642), np.float64(0.3360187986080607), np.float64(0.33599094965481896), np.float64(0.335963200045686), np.float64(0.3359355493418459), np.float64(0.33590799710688257), np.float64(0.3358805429067631), np.float64(0.3358531863098221), np.float64(0.335825926886746), np.float64(0.3357987642105575), np.float64(0.3357716978566004), np.float64(0.3357447274025242), np.float64(0.33571785242826846), np.float64(0.33569107251604796), np.float64(0.3356643872503384), np.float64(0.3356377962178605), np.float64(0.33561129900756614), np.float64(0.33558489521062296), np.float64(0.3355585844204007), np.float64(0.3355323662324561), np.float64(0.3355062402445191), np.float64(0.3354802060564785), np.float64(0.3354542632703681), np.float64(0.3354284114903519), np.float64(0.3354026503227116), np.float64(0.33537697937583205), np.float64(0.33535139826018756), np.float64(0.3353259065883289), np.float64(0.3353005039748692), np.float64(0.33527519003647127), np.float64(0.33524996439183397), np.float64(0.3352248266616795), np.float64(0.33519977646873983), np.float64(0.3351748134377443), np.float64(0.3351499371954064), np.float64(0.3351251473704113), np.float64(0.33510044359340335), np.float64(0.33507582549697323), np.float64(0.3350512927156457), np.float64(0.335026844885867), np.float64(0.33500248164599317), np.float64(0.3349782026362774), np.float64(0.3349540074988581), np.float64(0.3349298958777471), np.float64(0.33490586741881734), np.float64(0.3348819217697917), np.float64(0.3348580585802306), np.float64(0.33483427750152117), np.float64(0.33481057818686494), np.float64(0.3347869602912668), np.float64(0.334763423471524), np.float64(0.33473996738621387), np.float64(0.33471659169568363), np.float64(0.3346932960620389), np.float64(0.33467008014913235), np.float64(0.3346469436225533), np.float64(0.33462388614961674), np.float64(0.3346009073993522), np.float64(0.3345780070424936), np.float64(0.3345551847514681), np.float64(0.33453244020038575), np.float64(0.3345097730650291), np.float64(0.3344871830228431), np.float64(0.33446466975292394), np.float64(0.33444223293600966), np.float64(0.3344198722544697), np.float64(0.3343975873922943), np.float64(0.33437537803508555), np.float64(0.3343532438700468), np.float64(0.3343311845859723), np.float64(0.33430919987323854), np.float64(0.3342872894237939), np.float64(0.33426545293114857), np.float64(0.33424369009036603), np.float64(0.3342220005980526), np.float64(0.3342003841523484), np.float64(0.3341788404529179), np.float64(0.33415736920094075), np.float64(0.3341359700991022), np.float64(0.3341146428515843), np.float64(0.33409338716405673), np.float64(0.33407220274366733), np.float64(0.3340510892990339), np.float64(0.3340300465402343), np.float64(0.3340090741787986), np.float64(0.3339881719276996), np.float64(0.3339673395013443), np.float64(0.33394657661556537), np.float64(0.33392588298761267), np.float64(0.33390525833614393), np.float64(0.3338847023812174), np.float64(0.3338642148442825), np.float64(0.3338437954481723), np.float64(0.3338234439170941), np.float64(0.33380315997662235), np.float64(0.33378294335368985), np.float64(0.3337627937765798), np.float64(0.3337427109749174), np.float64(0.3337226946796624), np.float64(0.3337027446231009), np.float64(0.33368286053883733), np.float64(0.3336630421617865), np.float64(0.33364328922816633), np.float64(0.33362360147548975), np.float64(0.333603978642557), np.float64(0.3335844204694481), np.float64(0.3335649266975153), np.float64(0.3335454970693757), np.float64(0.33352613132890313), np.float64(0.333506829221222), np.float64(0.3334875904926984), np.float64(0.3334684148909338), np.float64(0.33344930216475804), np.float64(0.3334302520642209), np.float64(0.3334112643405862), np.float64(0.3333923387463238), np.float64(0.3333734750351035), np.float64(0.33335467296178656), np.float64(0.3333359322824204), np.float64(0.33331725275423046), np.float64(0.33329863413561406), np.float64(0.3332800761861331), np.float64(0.3332615786665075), np.float64(0.33324314133860866), np.float64(0.3332247639654523), np.float64(0.33320644631119234), np.float64(0.33318818814111395), np.float64(0.33316998922162716), np.float64(0.3331518493202606), np.float64(0.3331337682056542), np.float64(0.33311574564755386), np.float64(0.33309778141680463), np.float64(0.333079875285344), np.float64(0.3330620270261962), np.float64(0.3330442364134656), np.float64(0.3330265032223308), np.float64(0.3330088272290381), np.float64(0.33299120821089584), np.float64(0.33297364594626805), np.float64(0.33295614021456843), np.float64(0.3329386907962542), np.float64(0.33292129747282095), np.float64(0.33290396002679534), np.float64(0.3328866782417306), np.float64(0.3328694519021998), np.float64(0.3328522807937908), np.float64(0.3328351647030998), np.float64(0.3328181034177258), np.float64(0.3328010967262651), np.float64(0.33278414441830584), np.float64(0.332767246284422), np.float64(0.33275040211616796), np.float64(0.33273361170607313), np.float64(0.33271687484763607), np.float64(0.33270019133531975), np.float64(0.33268356096454543), np.float64(0.3326669835316875), np.float64(0.3326504588340684), np.float64(0.33263398666995303), np.float64(0.3326175668385433), np.float64(0.33260119913997355), np.float64(0.3325848833753046), np.float64(0.3325686193465192), np.float64(0.3325524068565163), np.float64(0.33253624570910667), np.float64(0.3325201357090067), np.float64(0.3325040766618349), np.float64(0.3324880683741056), np.float64(0.33247211065322463), np.float64(0.3324562033074842), np.float64(0.33244034614605783), np.float64(0.3324245389789961), np.float64(0.33240878161722076), np.float64(0.33239307387252104), np.float64(0.33237741555754824), np.float64(0.3323618064858107), np.float64(0.3323462464716703), np.float64(0.33233073533033614), np.float64(0.33231527287786117), np.float64(0.3322998589311368), np.float64(0.332284493307889), np.float64(0.33226917582667315), np.float64(0.3322539063068696), np.float64(0.33223868456867917), np.float64(0.33222351043311915), np.float64(0.3322083837220183), np.float64(0.33219330425801236), np.float64(0.33217827186454013), np.float64(0.3321632863658387), np.float64(0.3321483475869396), np.float64(0.33213345535366384), np.float64(0.33211860949261796), np.float64(0.33210380983119026), np.float64(0.33208905619754536), np.float64(0.3320743484206212), np.float64(0.33205968633012445), np.float64(0.33204506975652603), np.float64(0.33203049853105765), np.float64(0.3320159724857069), np.float64(0.33200149145321406), np.float64(0.33198705526706734), np.float64(0.33197266376149925), np.float64(0.33195831677148235), np.float64(0.33194401413272595), np.float64(0.3319297556816709), np.float64(0.3319155412554872), np.float64(0.3319013706920689), np.float64(0.3318872438300308), np.float64(0.3318731605087044), np.float64(0.33185912056813444), np.float64(0.33184512384907455), np.float64(0.3318311701929839), np.float64(0.3318172594420232), np.float64(0.3318033914390517), np.float64(0.33178956602762183), np.float64(0.3317757830519776), np.float64(0.33176204235704904), np.float64(0.3317483437884505), np.float64(0.33173468719247506), np.float64(0.33172107241609233), np.float64(0.3317074993069445), np.float64(0.33169396771334275), np.float64(0.33168047748426327), np.float64(0.33166702846934476), np.float64(0.3316536205188842), np.float64(0.33164025348383364), np.float64(0.3316269272157967), np.float64(0.33161364156702516), np.float64(0.3316003963904157), np.float64(0.33158719153950644), np.float64(0.3315740268684735), np.float64(0.33156090223212775), np.float64(0.3315478174859118), np.float64(0.3315347724858959), np.float64(0.33152176708877534), np.float64(0.3315088011518676), np.float64(0.331495874533108), np.float64(0.3314829870910472), np.float64(0.3314701386848479), np.float64(0.33145732917428167), np.float64(0.331444558419726), np.float64(0.33143182628216034), np.float64(0.3314191326231643), np.float64(0.33140647730491357), np.float64(0.33139386019017697), np.float64(0.3313812811423139), np.float64(0.33136874002527056), np.float64(0.33135623670357783), np.float64(0.33134377104234725), np.float64(0.33133134290726923), np.float64(0.33131895216460855), np.float64(0.33130659868120294), np.float64(0.3312942823244594), np.float64(0.3312820029623513), np.float64(0.33126976046341544), np.float64(0.3312575546967496), np.float64(0.331245385532009), np.float64(0.3312332528394044), np.float64(0.3312211564896983), np.float64(0.33120909635420265), np.float64(0.3311970723047759), np.float64(0.3311850842138205), np.float64(0.3311731319542799), np.float64(0.33116121539963556), np.float64(0.331149334423905), np.float64(0.3311374889016381), np.float64(0.3311256787079153), np.float64(0.3311139037183443), np.float64(0.3311021638090577), np.float64(0.3310904588567104), np.float64(0.3310787887384767), np.float64(0.33106715333204806), np.float64(0.33105555251563), np.float64(0.33104398616794), np.float64(0.3310324541682048), np.float64(0.33102095639615775), np.float64(0.3310094927320362), np.float64(0.330998063056579), np.float64(0.33098666725102466), np.float64(0.3309753051971075), np.float64(0.3309639767770565), np.float64(0.33095268187359206), np.float64(0.330941420369924), np.float64(0.3309301921497487), np.float64(0.33091899709724687), np.float64(0.33090783509708144), np.float64(0.3308967060343944), np.float64(0.3308856097948054), np.float64(0.3308745462644088), np.float64(0.3308635153297713), np.float64(0.3308525168779297), np.float64(0.33084155079638866), np.float64(0.3308306169731184), np.float64(0.33081971529655213), np.float64(0.3308088456555843), np.float64(0.3307980079395676), np.float64(0.3307872020383115), np.float64(0.3307764278420795), np.float64(0.33076568524158667), np.float64(0.33075497412799804), np.float64(0.3307442943929265), np.float64(0.3307336459284295), np.float64(0.33072302862700814), np.float64(0.3307124423816043), np.float64(0.33070188708559883), np.float64(0.3306913626328087), np.float64(0.33068086891748605), np.float64(0.3306704058343151), np.float64(0.33065997327841046), np.float64(0.33064957114531474), np.float64(0.33063919933099706), np.float64(0.33062885773185036), np.float64(0.3306185462446892), np.float64(0.33060826476674915), np.float64(0.33059801319568266), np.float64(0.33058779142955846), np.float64(0.3305775993668592), np.float64(0.33056743690647944), np.float64(0.33055730394772365), np.float64(0.33054720039030383), np.float64(0.3305371261343386), np.float64(0.33052708108035), np.float64(0.3305170651292623), np.float64(0.3305070781824002), np.float64(0.3304971201414861), np.float64(0.33048719090863893), np.float64(0.33047729038637197), np.float64(0.3304674184775911), np.float64(0.3304575750855928), np.float64(0.33044776011406224), np.float64(0.33043797346707127), np.float64(0.33042821504907727), np.float64(0.33041848476492025), np.float64(0.33040878251982225), np.float64(0.3303991082193843), np.float64(0.3303894617695854), np.float64(0.33037984307678053), np.float64(0.3303702520476988), np.float64(0.33036068858944195), np.float64(0.330351152609482), np.float64(0.33034164401566), np.float64(0.33033216271618393), np.float64(0.33032270861962776), np.float64(0.3303132816349285), np.float64(0.330303881671385), np.float64(0.33029450863865745), np.float64(0.33028516244676304), np.float64(0.3302758430060767), np.float64(0.33026655022732854), np.float64(0.330257284021602), np.float64(0.3302480443003323), np.float64(0.3302388309753049), np.float64(0.3302296439586537), np.float64(0.33022048316285973), np.float64(0.33021134850074896), np.float64(0.3302022398854916), np.float64(0.3301931572305991), np.float64(0.3301841004499242), np.float64(0.3301750694576578), np.float64(0.33016606416832844), np.float64(0.33015708449680037), np.float64(0.33014813035827184), np.float64(0.3301392016682741), np.float64(0.3301302983426687), np.float64(0.3301214202976473), np.float64(0.33011256744972944), np.float64(0.33010373971576085), np.float64(0.3300949370129124), np.float64(0.3300861592586786), np.float64(0.33007740637087535), np.float64(0.3300686782676394), np.float64(0.3300599748674266), np.float64(0.33005129608900974), np.float64(0.3300426418514781), np.float64(0.33003401207423544), np.float64(0.3300254066769983), np.float64(0.3300168255797957), np.float64(0.33000826870296596), np.float64(0.329999735967157), np.float64(0.32999122729332353), np.float64(0.32998274260272653), np.float64(0.32997428181693167), np.float64(0.3299658448578078), np.float64(0.32995743164752533), np.float64(0.3299490421085552), np.float64(0.3299406761636676), np.float64(0.3299323337359301), np.float64(0.3299240147487068), np.float64(0.32991571912565676), np.float64(0.3299074467907326), np.float64(0.3298991976681792), np.float64(0.32989097168253245), np.float64(0.3298827687586181), np.float64(0.32987458882154996), np.float64(0.3298664317967287), np.float64(0.3298582976098413), np.float64(0.32985018618685846), np.float64(0.3298420974540346), np.float64(0.3298340313379056), np.float64(0.3298259877652881), np.float64(0.3298179666632779), np.float64(0.3298099679592492), np.float64(0.3298019915808527), np.float64(0.3297940374560144), np.float64(0.32978610551293536), np.float64(0.3297781956800889), np.float64(0.3297703078862209), np.float64(0.32976244206034716), np.float64(0.3297545981317535), np.float64(0.3297467760299935), np.float64(0.32973897568488825), np.float64(0.32973119702652404), np.float64(0.32972343998525205), np.float64(0.32971570449168697), np.float64(0.3297079904767056), np.float64(0.3297002978714462), np.float64(0.32969262660730614), np.float64(0.3296849766159423), np.float64(0.329677347829269), np.float64(0.3296697401794567), np.float64(0.32966215359893153), np.float64(0.32965458802037345), np.float64(0.3296470433767162), np.float64(0.3296395196011444), np.float64(0.3296320166270943), np.float64(0.32962453438825157), np.float64(0.3296170728185504), np.float64(0.32960963185217246), np.float64(0.32960221142354623), np.float64(0.32959481146734493), np.float64(0.32958743191848644), np.float64(0.3295800727121313), np.float64(0.32957273378368285), np.float64(0.32956541506878473), np.float64(0.3295581165033211), np.float64(0.32955083802341445), np.float64(0.32954357956542585), np.float64(0.32953634106595253), np.float64(0.3295291224618275), np.float64(0.32952192369011896), np.float64(0.32951474468812847), np.float64(0.3295075853933904), np.float64(0.32950044574367077), np.float64(0.3294933256769661), np.float64(0.3294862251315027), np.float64(0.3294791440457354), np.float64(0.32947208235834696), np.float64(0.3294650400082465), np.float64(0.32945801693456866), np.float64(0.3294510130766731), np.float64(0.32944402837414305), np.float64(0.32943706276678447), np.float64(0.32943011619462514), np.float64(0.3294231885979134), np.float64(0.3294162799171177), np.float64(0.32940939009292547), np.float64(0.32940251906624146), np.float64(0.3293956667781881), np.float64(0.32938883317010365), np.float64(0.32938201818354146), np.float64(0.3293752217602689), np.float64(0.32936844384226704), np.float64(0.32936168437172886), np.float64(0.3293549432910592), np.float64(0.32934822054287294), np.float64(0.32934151606999496), np.float64(0.3293348298154586), np.float64(0.32932816172250545), np.float64(0.32932151173458346), np.float64(0.3293148797953471), np.float64(0.32930826584865575), np.float64(0.32930166983857306), np.float64(0.32929509170936616), np.float64(0.32928853140550485), np.float64(0.3292819888716604), np.float64(0.3292754640527048), np.float64(0.32926895689371016), np.float64(0.32926246733994796), np.float64(0.3292559953368874), np.float64(0.32924954083019525), np.float64(0.3292431037657351), np.float64(0.3292366840895662), np.float64(0.3292302817479424), np.float64(0.32922389668731183), np.float64(0.3292175288543159), np.float64(0.3292111781957883), np.float64(0.32920484465875466), np.float64(0.3291985281904312), np.float64(0.3291922287382238), np.float64(0.32918594624972813), np.float64(0.3291796806727278), np.float64(0.3291734319551944), np.float64(0.32916720004528593), np.float64(0.32916098489134665), np.float64(0.329154786441906), np.float64(0.3291486046456778), np.float64(0.32914243945155974), np.float64(0.3291362908086322), np.float64(0.3291301586661577), np.float64(0.32912404297358044), np.float64(0.32911794368052455), np.float64(0.32911186073679505), np.float64(0.3291057940923751), np.float64(0.32909974369742667), np.float64(0.3290937095022892), np.float64(0.32908769145747907), np.float64(0.32908168951368877), np.float64(0.329075703621786), np.float64(0.3290697337328134), np.float64(0.32906377979798734), np.float64(0.3290578417686975), np.float64(0.32905191959650604), np.float64(0.3290460132331465), np.float64(0.3290401226305241), np.float64(0.32903424774071416), np.float64(0.3290283885159612), np.float64(0.3290225449086794), np.float64(0.32901671687145045), np.float64(0.3290109043570242), np.float64(0.3290051073183169), np.float64(0.328999325708411), np.float64(0.32899355948055464), np.float64(0.3289878085881605), np.float64(0.32898207298480564), np.float64(0.3289763526242301), np.float64(0.3289706474603369), np.float64(0.3289649574471911), np.float64(0.3289592825390194), np.float64(0.3289536226902088), np.float64(0.3289479778553067), np.float64(0.3289423479890198), np.float64(0.3289367330462137), np.float64(0.3289311329819118), np.float64(0.3289255477512952), np.float64(0.32891997730970185), np.float64(0.328914421612626), np.float64(0.32890888061571694), np.float64(0.32890335427477924), np.float64(0.3288978425457717), np.float64(0.32889234538480694), np.float64(0.32888686274814993), np.float64(0.32888139459221893), np.float64(0.3288759408735833), np.float64(0.3288705015489637), np.float64(0.32886507657523156), np.float64(0.3288596659094079), np.float64(0.3288542695086632), np.float64(0.32884888733031675), np.float64(0.32884351933183575), np.float64(0.328838165470835), np.float64(0.32883282570507616), np.float64(0.32882749999246735), np.float64(0.3288221882910621), np.float64(0.3288168905590594), np.float64(0.32881160675480237), np.float64(0.3288063368367785), np.float64(0.3288010807636185), np.float64(0.3287958384940958), np.float64(0.32879060998712606), np.float64(0.3287853952017666), np.float64(0.3287801940972159), np.float64(0.32877500663281284), np.float64(0.3287698327680361), np.float64(0.3287646724625042), np.float64(0.32875952567597383), np.float64(0.32875439236834075), np.float64(0.3287492724996376), np.float64(0.3287441660300347), np.float64(0.3287390729198388), np.float64(0.3287339931294926), np.float64(0.32872892661957465), np.float64(0.328723873350798), np.float64(0.3287188332840105), np.float64(0.32871380638019376), np.float64(0.32870879260046276), np.float64(0.3287037919060654), np.float64(0.32869880425838155), np.float64(0.32869382961892335), np.float64(0.3286888679493338), np.float64(0.32868391921138673), np.float64(0.3286789833669862), np.float64(0.328674060378166), np.float64(0.32866915020708887), np.float64(0.32866425281604655), np.float64(0.3286593681674587), np.float64(0.32865449622387277), np.float64(0.32864963694796295), np.float64(0.32864479030253074), np.float64(0.3286399562505032), np.float64(0.3286351347549333), np.float64(0.3286303257789989), np.float64(0.3286255292860028), np.float64(0.32862074523937185), np.float64(0.3286159736026565), np.float64(0.3286112143395303), np.float64(0.32860646741378974), np.float64(0.3286017327893534), np.float64(0.3285970104302613), np.float64(0.32859230030067543), np.float64(0.3285876023648775), np.float64(0.3285829165872705), np.float64(0.3285782429323767), np.float64(0.328573581364838), np.float64(0.32856893184941505), np.float64(0.32856429435098683), np.float64(0.32855966883455034), np.float64(0.32855505526522033), np.float64(0.32855045360822815), np.float64(0.32854586382892215), np.float64(0.3285412858927666), np.float64(0.3285367197653413), np.float64(0.32853216541234165), np.float64(0.3285276227995775), np.float64(0.32852309189297313), np.float64(0.3285185726585668), np.float64(0.32851406506251), np.float64(0.32850956907106743), np.float64(0.3285050846506164), np.float64(0.32850061176764594), np.float64(0.32849615038875707), np.float64(0.32849170048066223), np.float64(0.3284872620101844), np.float64(0.3284828349442568), np.float64(0.3284784192499233), np.float64(0.32847401489433653), np.float64(0.32846962184475875), np.float64(0.32846524006856065), np.float64(0.32846086953322146), np.float64(0.3284565102063279), np.float64(0.3284521620555745), np.float64(0.3284478250487626), np.float64(0.3284434991538004), np.float64(0.3284391843387018), np.float64(0.3284348805715872), np.float64(0.32843058782068196), np.float64(0.32842630605431633), np.float64(0.32842203524092545), np.float64(0.3284177753490487), np.float64(0.3284135263473289), np.float64(0.3284092882045122), np.float64(0.32840506088944843), np.float64(0.3284008443710894), np.float64(0.32839663861848906), np.float64(0.3283924436008036), np.float64(0.32838825928729043), np.float64(0.32838408564730814), np.float64(0.3283799226503157), np.float64(0.32837577026587267), np.float64(0.32837162846363793), np.float64(0.3283674972133708), np.float64(0.32836337648492897), np.float64(0.328359266248269), np.float64(0.3283551664734461), np.float64(0.3283510771306133), np.float64(0.32834699819002133), np.float64(0.3283429296220181), np.float64(0.3283388713970485), np.float64(0.32833482348565385), np.float64(0.32833078585847175), np.float64(0.3283267584862355), np.float64(0.3283227413397738), np.float64(0.3283187343900107), np.float64(0.3283147376079646), np.float64(0.3283107509647485), np.float64(0.32830677443156925), np.float64(0.32830280797972744), np.float64(0.32829885158061684), np.float64(0.32829490520572446), np.float64(0.3282909688266296), np.float64(0.3282870424150038), np.float64(0.3282831259426108), np.float64(0.32827921938130544), np.float64(0.3282753227030342), np.float64(0.3282714358798342), np.float64(0.3282675588838331), np.float64(0.3282636916872489), np.float64(0.3282598342623892), np.float64(0.3282559865816512), np.float64(0.32825214861752133), np.float64(0.32824832034257506), np.float64(0.32824450172947583), np.float64(0.3282406927509758), np.float64(0.3282368933799146), np.float64(0.3282331035892198), np.float64(0.32822932335190563), np.float64(0.3282255526410739), np.float64(0.3282217914299121), np.float64(0.32821803969169466), np.float64(0.3282142973997815), np.float64(0.3282105645276185), np.float64(0.32820684104873626), np.float64(0.328203126936751), np.float64(0.32819942216536313), np.float64(0.3281957267083574), np.float64(0.32819204053960266), np.float64(0.32818836363305154), np.float64(0.32818469596273986), np.float64(0.32818103750278704), np.float64(0.3281773882273943), np.float64(0.3281737481108463), np.float64(0.3281701171275093), np.float64(0.3281664952518315), np.float64(0.32816288245834296), np.float64(0.32815927872165457), np.float64(0.32815568401645856), np.float64(0.32815209831752773), np.float64(0.32814852159971475), np.float64(0.32814495383795306), np.float64(0.32814139500725537), np.float64(0.3281378450827144), np.float64(0.32813430403950133), np.float64(0.32813077185286704), np.float64(0.32812724849814023), np.float64(0.32812373395072864), np.float64(0.3281202281861174), np.float64(0.3281167311798698), np.float64(0.3281132429076265), np.float64(0.3281097633451052), np.float64(0.3281062924681008), np.float64(0.32810283025248455), np.float64(0.32809937667420397), np.float64(0.328095931709283), np.float64(0.32809249533382095), np.float64(0.3280890675239929), np.float64(0.328085648256049), np.float64(0.32808223750631443), np.float64(0.3280788352511892), np.float64(0.32807544146714734), np.float64(0.3280720561307374), np.float64(0.3280686792185817), np.float64(0.3280653107073758), np.float64(0.32806195057388937), np.float64(0.32805859879496446), np.float64(0.32805525534751606), np.float64(0.32805192020853174), np.float64(0.3280485933550715), np.float64(0.3280452747642673), np.float64(0.32804196441332273), np.float64(0.32803866227951295), np.float64(0.32803536834018443), np.float64(0.3280320825727543), np.float64(0.32802880495471093), np.float64(0.3280255354636127), np.float64(0.32802227407708856), np.float64(0.32801902077283696), np.float64(0.3280157755286264), np.float64(0.3280125383222951), np.float64(0.32800930913174986), np.float64(0.328006087934967), np.float64(0.32800287470999084), np.float64(0.32799966943493497), np.float64(0.32799647208798083), np.float64(0.3279932826473779), np.float64(0.3279901010914433), np.float64(0.3279869273985615), np.float64(0.32798376154718456), np.float64(0.32798060351583147), np.float64(0.32797745328308775), np.float64(0.3279743108276056), np.float64(0.3279711761281036), np.float64(0.32796804916336614), np.float64(0.32796492991224385), np.float64(0.32796181835365246), np.float64(0.32795871446657326), np.float64(0.32795561823005276), np.float64(0.3279525296232022), np.float64(0.3279494486251974), np.float64(0.32794637521527875), np.float64(0.32794330937275096), np.float64(0.32794025107698244), np.float64(0.3279372003074054), np.float64(0.32793415704351575), np.float64(0.3279311212648724), np.float64(0.32792809295109754), np.float64(0.32792507208187593), np.float64(0.32792205863695556), np.float64(0.32791905259614607), np.float64(0.3279160539393196), np.float64(0.32791306264641035), np.float64(0.327910078697414), np.float64(0.3279071020723881), np.float64(0.3279041327514511), np.float64(0.3279011707147828), np.float64(0.32789821594262364), np.float64(0.3278952684152753), np.float64(0.327892328113099), np.float64(0.3278893950165167), np.float64(0.32788646910601044), np.float64(0.3278835503621221), np.float64(0.3278806387654525), np.float64(0.3278777342966628), np.float64(0.3278748369364727), np.float64(0.3278719466656611), np.float64(0.3278690634650654), np.float64(0.32786618731558204), np.float64(0.32786331819816517), np.float64(0.3278604560938278), np.float64(0.3278576009836403), np.float64(0.32785475284873106), np.float64(0.3278519116702859), np.float64(0.32784907742954805), np.float64(0.3278462501078177), np.float64(0.3278434296864523), np.float64(0.3278406161468658), np.float64(0.32783780947052854), np.float64(0.3278350096389678), np.float64(0.32783221663376616), np.float64(0.32782943043656276), np.float64(0.32782665102905273), np.float64(0.32782387839298577), np.float64(0.3278211125101676), np.float64(0.3278183533624593), np.float64(0.3278156009317766), np.float64(0.3278128552000901), np.float64(0.32781011614942496), np.float64(0.3278073837618608), np.float64(0.32780465801953146), np.float64(0.3278019389046249), np.float64(0.32779922639938286), np.float64(0.32779652048610053), np.float64(0.32779382114712713), np.float64(0.32779112836486435), np.float64(0.32778844212176783), np.float64(0.3277857624003456), np.float64(0.32778308918315874), np.float64(0.3277804224528206), np.float64(0.32777776219199706), np.float64(0.32777510838340623), np.float64(0.3277724610098183), np.float64(0.327769820054055), np.float64(0.3277671854989901), np.float64(0.32776455732754856), np.float64(0.32776193552270677), np.float64(0.3277593200674923), np.float64(0.32775671094498365), np.float64(0.3277541081383099), np.float64(0.3277515116306511), np.float64(0.3277489214052373), np.float64(0.3277463374453492), np.float64(0.3277437597343173), np.float64(0.3277411882555224), np.float64(0.3277386229923945), np.float64(0.32773606392841353), np.float64(0.3277335110471088), np.float64(0.3277309643320589), np.float64(0.3277284237668911), np.float64(0.3277258893352822), np.float64(0.32772336102095717), np.float64(0.32772083880769), np.float64(0.3277183226793026), np.float64(0.3277158126196654), np.float64(0.327713308612697), np.float64(0.3277108106423638), np.float64(0.3277083186926799), np.float64(0.32770583274770704), np.float64(0.32770335279155416), np.float64(0.32770087880837784), np.float64(0.32769841078238154), np.float64(0.32769594869781576), np.float64(0.32769349253897767), np.float64(0.32769104229021084), np.float64(0.3276885979359059), np.float64(0.32768615946049967), np.float64(0.32768372684847435), np.float64(0.32768130008435903), np.float64(0.32767887915272825), np.float64(0.32767646403820233), np.float64(0.32767405472544686), np.float64(0.3276716511991734), np.float64(0.32766925344413805), np.float64(0.32766686144514234), np.float64(0.3276644751870328), np.float64(0.3276620946547005), np.float64(0.3276597198330812), np.float64(0.3276573507071552), np.float64(0.32765498726194703), np.float64(0.3276526294825253), np.float64(0.327650277354003), np.float64(0.32764793086153665), np.float64(0.32764558999032656), np.float64(0.3276432547256166), np.float64(0.3276409250526941), np.float64(0.32763860095688996), np.float64(0.32763628242357756), np.float64(0.3276339694381741), np.float64(0.3276316619861388), np.float64(0.32762936005297416), np.float64(0.32762706362422517), np.float64(0.327624772685479), np.float64(0.32762248722236526), np.float64(0.3276202072205558), np.float64(0.3276179326657643), np.float64(0.32761566354374627), np.float64(0.32761339984029925), np.float64(0.3276111415412618), np.float64(0.3276088886325145), np.float64(0.3276066410999789), np.float64(0.32760439892961807), np.float64(0.32760216210743553), np.float64(0.32759993061947607), np.float64(0.3275977044518252), np.float64(0.32759548359060897), np.float64(0.32759326802199407), np.float64(0.3275910577321876), np.float64(0.32758885270743643), np.float64(0.3275866529340279), np.float64(0.3275844583982894), np.float64(0.3275822690865878), np.float64(0.3275800849853297), np.float64(0.32757790608096155), np.float64(0.32757573235996895), np.float64(0.327573563808877), np.float64(0.3275714004142497), np.float64(0.32756924216269045), np.float64(0.3275670890408411), np.float64(0.32756494103538264), np.float64(0.32756279813303474), np.float64(0.3275606603205552), np.float64(0.3275585275847406), np.float64(0.32755639991242574), np.float64(0.32755427729048325), np.float64(0.3275521597058243), np.float64(0.32755004714539737), np.float64(0.3275479395961894), np.float64(0.3275458370452243), np.float64(0.3275437394795636), np.float64(0.3275416468863068), np.float64(0.32753955925259004), np.float64(0.32753747656558685), np.float64(0.327535398812508), np.float64(0.32753332598060086), np.float64(0.3275312580571496), np.float64(0.3275291950294753), np.float64(0.32752713688493523), np.float64(0.3275250836109236), np.float64(0.3275230351948704), np.float64(0.32752099162424225), np.float64(0.32751895288654137), np.float64(0.3275169189693064), np.float64(0.3275148898601116), np.float64(0.327512865546567), np.float64(0.32751084601631797), np.float64(0.3275088312570459), np.float64(0.3275068212564671), np.float64(0.3275048160023332), np.float64(0.32750281548243126), np.float64(0.3275008196845832), np.float64(0.32749882859664564), np.float64(0.3274968422065104), np.float64(0.3274948605021035), np.float64(0.32749288347138616), np.float64(0.3274909111023534), np.float64(0.3274889433830352), np.float64(0.32748698030149526), np.float64(0.3274850218458317), np.float64(0.3274830680041767), np.float64(0.3274811187646961), np.float64(0.3274791741155899), np.float64(0.3274772340450913), np.float64(0.32747529854146756), np.float64(0.3274733675930192), np.float64(0.3274714411880801), np.float64(0.3274695193150172), np.float64(0.32746760196223107), np.float64(0.327465689118155), np.float64(0.32746378077125515), np.float64(0.32746187691003065), np.float64(0.3274599775230134), np.float64(0.3274580825987679), np.float64(0.32745619212589105), np.float64(0.32745430609301207), np.float64(0.32745242448879275), np.float64(0.32745054730192713), np.float64(0.3274486745211409), np.float64(0.3274468061351922), np.float64(0.32744494213287084), np.float64(0.3274430825029985), np.float64(0.3274412272344284), np.float64(0.3274393763160455), np.float64(0.3274375297367663), np.float64(0.32743568748553864), np.float64(0.32743384955134125), np.float64(0.3274320159231847), np.float64(0.3274301865901103), np.float64(0.3274283615411901), np.float64(0.3274265407655277), np.float64(0.32742472425225666), np.float64(0.327422911990542), np.float64(0.3274211039695789), np.float64(0.32741930017859294), np.float64(0.3274175006068405), np.float64(0.327415705243608), np.float64(0.3274139140782119), np.float64(0.3274121270999992), np.float64(0.32741034429834653), np.float64(0.3274085656626605), np.float64(0.3274067911823778), np.float64(0.3274050208469646), np.float64(0.32740325464591663), np.float64(0.3274014925687595), np.float64(0.3273997346050479), np.float64(0.3273979807443659), np.float64(0.3273962309763271), np.float64(0.327394485290574), np.float64(0.3273927436767784), np.float64(0.32739100612464095), np.float64(0.32738927262389095), np.float64(0.3273875431642869), np.float64(0.327385817735616), np.float64(0.32738409632769355), np.float64(0.32738237893036387), np.float64(0.32738066553349965), np.float64(0.3273789561270017), np.float64(0.32737725070079937), np.float64(0.3273755492448498), np.float64(0.3273738517491386), np.float64(0.32737215820367915), np.float64(0.32737046859851276), np.float64(0.32736878292370847), np.float64(0.32736710116936335), np.float64(0.3273654233256017), np.float64(0.3273637493825758), np.float64(0.3273620793304648), np.float64(0.3273604131594758), np.float64(0.3273587508598429), np.float64(0.3273570924218277), np.float64(0.32735543783571835), np.float64(0.3273537870918305), np.float64(0.32735214018050685), np.float64(0.3273504970921164), np.float64(0.3273488578170554), np.float64(0.3273472223457468), np.float64(0.3273455906686398), np.float64(0.32734396277621064), np.float64(0.3273423386589615), np.float64(0.3273407183074211), np.float64(0.3273391017121447), np.float64(0.3273374888637135), np.float64(0.3273358797527349), np.float64(0.32733427436984225), np.float64(0.3273326727056948), np.float64(0.3273310747509779), np.float64(0.3273294804964026), np.float64(0.32732788993270573), np.float64(0.3273263030506494), np.float64(0.32732471984102185), np.float64(0.32732314029463633), np.float64(0.3273215644023314), np.float64(0.32731999215497165), np.float64(0.32731842354344615), np.float64(0.3273168585586693), np.float64(0.327315297191581), np.float64(0.32731373943314557), np.float64(0.3273121852743528), np.float64(0.3273106347062167), np.float64(0.3273090877197767), np.float64(0.32730754430609643), np.float64(0.3273060044562644), np.float64(0.32730446816139375), np.float64(0.3273029354126216), np.float64(0.3273014062011101), np.float64(0.3272998805180453), np.float64(0.32729835835463755), np.float64(0.32729683970212137), np.float64(0.32729532455175564), np.float64(0.3272938128948226), np.float64(0.3272923047226293), np.float64(0.3272908000265059), np.float64(0.32728929879780677), np.float64(0.32728780102790983), np.float64(0.32728630670821685), np.float64(0.32728481583015295), np.float64(0.32728332838516666), np.float64(0.32728184436473046), np.float64(0.32728036376033953), np.float64(0.32727888656351284), np.float64(0.32727741276579225), np.float64(0.3272759423587429), np.float64(0.32727447533395304), np.float64(0.32727301168303385), np.float64(0.32727155139761954), np.float64(0.32727009446936695), np.float64(0.32726864088995594), np.float64(0.327267190651089), np.float64(0.32726574374449136), np.float64(0.3272643001619105), np.float64(0.32726285989511694), np.float64(0.3272614229359034), np.float64(0.32725998927608463), np.float64(0.32725855890749805), np.float64(0.32725713182200344), np.float64(0.3272557080114826), np.float64(0.3272542874678393), np.float64(0.32725287018299937), np.float64(0.3272514561489108), np.float64(0.32725004535754326), np.float64(0.3272486378008884), np.float64(0.32724723347095974), np.float64(0.3272458323597921), np.float64(0.32724443445944235), np.float64(0.32724303976198876), np.float64(0.32724164825953117), np.float64(0.3272402599441904), np.float64(0.32723887480810965), np.float64(0.3272374928434523), np.float64(0.3272361140424039), np.float64(0.32723473839717043), np.float64(0.32723336589997937), np.float64(0.3272319965430795), np.float64(0.3272306303187401), np.float64(0.3272292672192513), np.float64(0.32722790723692474), np.float64(0.32722655036409243), np.float64(0.32722519659310684), np.float64(0.3272238459163417), np.float64(0.3272224983261909), np.float64(0.3272211538150693), np.float64(0.32721981237541165), np.float64(0.32721847399967363), np.float64(0.32721713868033114), np.float64(0.32721580640988013), np.float64(0.32721447718083735), np.float64(0.3272131509857391), np.float64(0.32721182781714214), np.float64(0.3272105076676232), np.float64(0.3272091905297791), np.float64(0.32720787639622656), np.float64(0.3272065652596019), np.float64(0.3272052571125616), np.float64(0.3272039519477819), np.float64(0.32720264975795843), np.float64(0.3272013505358066), np.float64(0.3272000542740617), np.float64(0.327198760965478), np.float64(0.3271974706028296), np.float64(0.32719618317890997), np.float64(0.32719489868653173), np.float64(0.327193617118527), np.float64(0.3271923384677468), np.float64(0.3271910627270619), np.float64(0.3271897898893617), np.float64(0.32718851994755466), np.float64(0.3271872528945685), np.float64(0.3271859887233497), np.float64(0.3271847274268636), np.float64(0.3271834689980946), np.float64(0.3271822134300456), np.float64(0.3271809607157385), np.float64(0.32717971084821335), np.float64(0.32717846382052934), np.float64(0.3271772196257641), np.float64(0.3271759782570135), np.float64(0.3271747397073919), np.float64(0.3271735039700323), np.float64(0.327172271038086), np.float64(0.3271710409047223), np.float64(0.3271698135631288), np.float64(0.3271685890065114), np.float64(0.3271673672280941), np.float64(0.3271661482211188), np.float64(0.3271649319788455), np.float64(0.32716371849455234), np.float64(0.3271625077615348), np.float64(0.3271612997731069), np.float64(0.32716009452260014), np.float64(0.3271588920033634), np.float64(0.3271576922087639), np.float64(0.327156495132186), np.float64(0.32715530076703186), np.float64(0.3271541091067211), np.float64(0.327152920144691), np.float64(0.32715173387439583), np.float64(0.3271505502893077), np.float64(0.32714936938291583), np.float64(0.32714819114872656), np.float64(0.3271470155802638), np.float64(0.3271458426710685), np.float64(0.32714467241469825), np.float64(0.3271435048047286), np.float64(0.32714233983475144), np.float64(0.32714117749837596), np.float64(0.3271400177892279), np.float64(0.3271388607009502), np.float64(0.32713770622720256), np.float64(0.3271365543616615), np.float64(0.32713540509802), np.float64(0.3271342584299879), np.float64(0.32713311435129155), np.float64(0.3271319728556742), np.float64(0.3271308339368951), np.float64(0.32712969758873045), np.float64(0.3271285638049727), np.float64(0.32712743257943044), np.float64(0.3271263039059288), np.float64(0.3271251777783094), np.float64(0.3271240541904297), np.float64(0.32712293313616364), np.float64(0.32712181460940115), np.float64(0.3271206986040483), np.float64(0.327119585114027), np.float64(0.32711847413327555), np.float64(0.327117365655748), np.float64(0.32711625967541424), np.float64(0.32711515618625997), np.float64(0.32711405518228687), np.float64(0.32711295665751244), np.float64(0.3271118606059696), np.float64(0.32711076702170727), np.float64(0.32710967589878975), np.float64(0.32710858723129693), np.float64(0.3271075010133244), np.float64(0.32710641723898326), np.float64(0.32710533590239976), np.float64(0.32710425699771595), np.float64(0.3271031805190889), np.float64(0.32710210646069093), np.float64(0.3271010348167102), np.float64(0.32709996558134946), np.float64(0.3270988987488269), np.float64(0.32709783431337586), np.float64(0.32709677226924466), np.float64(0.32709571261069675), np.float64(0.3270946553320106), np.float64(0.32709360042747965), np.float64(0.3270925478914122), np.float64(0.32709149771813123), np.float64(0.32709044990197494), np.float64(0.3270894044372961), np.float64(0.32708836131846214), np.float64(0.3270873205398554), np.float64(0.32708628209587265), np.float64(0.3270852459809256), np.float64(0.32708421218944), np.float64(0.3270831807158567), np.float64(0.3270821515546306), np.float64(0.3270811247002315), np.float64(0.32708010014714317), np.float64(0.32707907788986373), np.float64(0.32707805792290623), np.float64(0.3270770402407972), np.float64(0.3270760248380779), np.float64(0.3270750117093037), np.float64(0.327074000849044), np.float64(0.3270729922518823), np.float64(0.3270719859124167), np.float64(0.3270709818252585), np.float64(0.3270699799850336), np.float64(0.3270689803863816), np.float64(0.3270679830239562), np.float64(0.32706698789242444), np.float64(0.3270659949864681), np.float64(0.32706500430078217), np.float64(0.32706401583007516), np.float64(0.32706302956906974), np.float64(0.32706204551250234), np.float64(0.3270610636551226), np.float64(0.32706008399169406), np.float64(0.3270591065169936), np.float64(0.32705813122581195), np.float64(0.32705715811295294), np.float64(0.32705618717323415), np.float64(0.32705521840148627), np.float64(0.32705425179255354), np.float64(0.3270532873412936), np.float64(0.3270523250425774), np.float64(0.3270513648912886), np.float64(0.3270504068823249), np.float64(0.32704945101059657), np.float64(0.32704849727102714), np.float64(0.3270475456585535), np.float64(0.32704659616812537), np.float64(0.3270456487947052), np.float64(0.32704470353326925), np.float64(0.327043760378806), np.float64(0.32704281932631707), np.float64(0.3270418803708169), np.float64(0.32704094350733315), np.float64(0.3270400087309057), np.float64(0.3270390760365875), np.float64(0.3270381454194443), np.float64(0.32703721687455434), np.float64(0.3270362903970086), np.float64(0.3270353659819109), np.float64(0.3270344436243772), np.float64(0.32703352331953645), np.float64(0.3270326050625299), np.float64(0.32703168884851114), np.float64(0.3270307746726466), np.float64(0.3270298625301147), np.float64(0.32702895241610636), np.float64(0.32702804432582516), np.float64(0.32702713825448654), np.float64(0.3270262341973185), np.float64(0.32702533214956103), np.float64(0.3270244321064665), np.float64(0.3270235340632994), np.float64(0.32702263801533626), np.float64(0.32702174395786593), np.float64(0.3270208518861892), np.float64(0.3270199617956188), np.float64(0.3270190736814793), np.float64(0.3270181875391077), np.float64(0.3270173033638527), np.float64(0.3270164211510748), np.float64(0.3270155408961464), np.float64(0.3270146625944518), np.float64(0.3270137862413869), np.float64(0.32701291183235964), np.float64(0.3270120393627895), np.float64(0.3270111688281078), np.float64(0.32701030022375716), np.float64(0.32700943354519224), np.float64(0.3270085687878792)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0:  [ 6.887e-01 -8.186e-01  3.864e+00 -6.952e-04]\n",
      "b0:  -2.1874516257246315\n"
     ]
    }
   ],
   "source": [
    "# plot the losses over iterations\n",
    "print(d2_losses)\n",
    "plt.figure()\n",
    "plt.plot(d2_losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Binary Cross Entropy Loss over Iterations')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# report the learnt parameter \n",
    "print(\"w0: \", d2_w0)\n",
    "print(\"b0: \", d2_b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0eebf983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.478 0.458 0.005 ... 0.002 0.112 0.138]\n",
      "Training accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "# classification accuracy\n",
    "#def logisticRegressionClassificationAccuracy:\n",
    "\n",
    "# COMPUTING TRAINING PREDICTION\n",
    "# Compute prediction w sigmoid function \n",
    "temp = np.dot(d2_xtrain, d2_w0) + d2_b0\n",
    "d2_train_pred = sigmoid(temp)\n",
    "n, m = d2_xtrain.shape\n",
    "print(d2_train_pred)\n",
    "train_acc = (d2_ytrain == d2_train_pred).sum() / n\n",
    "print(\"Training accuracy: \", train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5eeddc",
   "metadata": {},
   "source": [
    "### Task 2.2 Regularisation\n",
    "\n",
    "In this sub-task, you are going to apply $L_2$ regularisation to the logistic regression model. The regularised loss is\n",
    "\n",
    "$$\n",
    "L(\\mathbf{w}, b)= - \\frac{1}{n}\\sum_{i=1}^n {y^{(i)}} \\ln \\sigma^{(i)}+ (1- y^{(i)}) \\ln (1-\\sigma^{(i)}) + \\frac{\\lambda}{2} \\|\\mathbf{w}\\|_2^2\n",
    "$$\n",
    "\n",
    "* where $\\lambda >0$ is the regularisation hyperparameter\n",
    "\n",
    "* note that we do not usually apply penalty on the bias parameter $b$\n",
    "\n",
    "Implement the following method that fits a regularised logistic regression model with a given $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9362f937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T13:00:22.642606Z",
     "iopub.status.busy": "2025-02-13T13:00:22.642180Z",
     "iopub.status.idle": "2025-02-13T13:00:22.658793Z",
     "shell.execute_reply": "2025-02-13T13:00:22.657589Z",
     "shell.execute_reply.started": "2025-02-13T13:00:22.642562Z"
    }
   },
   "outputs": [],
   "source": [
    "def logistic_regression_reg_train(X, y, lr, lam = 0.01, tol= 1e-5, maxIters= 2000):\n",
    "    n, d = X.shape \n",
    "    # initialise w0, b0\n",
    "    w0 = np.zeros(d)\n",
    "    b0 = 0.0\n",
    "    losses = []\n",
    "    # loop until converge\n",
    "    # for i in range(maxIters):\n",
    "        \n",
    "    # return w0, b0, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fe2830",
   "metadata": {},
   "source": [
    "Complete and report the following two results\n",
    "* report the training loss and learnt parameter by setting $\\lambda=0.01$\n",
    "* report the testing performance for the regularised logistic regression model with $\\lambda=0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034441f1-227d-4c3a-825e-7aea11c78769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T13:00:22.660759Z",
     "iopub.status.busy": "2025-02-13T13:00:22.660316Z",
     "iopub.status.idle": "2025-02-13T13:00:22.677152Z",
     "shell.execute_reply": "2025-02-13T13:00:22.675886Z",
     "shell.execute_reply.started": "2025-02-13T13:00:22.660714Z"
    }
   },
   "outputs": [],
   "source": [
    "## run your algorithm and report your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5351e0f1-5105-416a-afd4-c33150a38809",
   "metadata": {},
   "source": [
    "### Task 2.3 Newton's method (extension)\n",
    "\n",
    "For convex loss functions, Newton's method converges much faster than a simple gradient descent algorithm. Implement a learning algorithm for the regularised logsitic regression with Newton's method. You are allowed to use auto-diff to finish this task.\n",
    "\n",
    "\n",
    "* use Newton's method to find the same logistic regression model\n",
    "\n",
    "* compare with gradient descent's learning curve, what do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db43f0bf-23aa-42c2-8b58-de318942586e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T13:00:22.679207Z",
     "iopub.status.busy": "2025-02-13T13:00:22.678747Z",
     "iopub.status.idle": "2025-02-13T13:00:22.694779Z",
     "shell.execute_reply": "2025-02-13T13:00:22.693544Z",
     "shell.execute_reply.started": "2025-02-13T13:00:22.679163Z"
    }
   },
   "outputs": [],
   "source": [
    "## run Newton's method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23535e1f-0d7f-46cc-ab1f-691f66f48ebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T13:00:22.696662Z",
     "iopub.status.busy": "2025-02-13T13:00:22.696226Z",
     "iopub.status.idle": "2025-02-13T13:00:22.712508Z",
     "shell.execute_reply": "2025-02-13T13:00:22.711289Z",
     "shell.execute_reply.started": "2025-02-13T13:00:22.696619Z"
    }
   },
   "outputs": [],
   "source": [
    "## report your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07610797-58a1-4cea-9079-00c76ac10c17",
   "metadata": {},
   "source": [
    "### Task 2.4 Weighted logistic regression (extension)\n",
    "\n",
    "Weighted logistic regression is a variant of the traditional logistic regression. It is usually used when the classification dataset is imbalanced. By assigning higher weights to the minority class and lower weights to the majority class, the model is encouraged to pay more attention to the minority class.\n",
    "\n",
    "Specifically, each training instance $y^{(i)}$ is given a positive weight $r^{(i)}$, and the weighted cross entropy loss becomes \n",
    "\n",
    "$$L(\\mathbf{w}, b) = - \\frac{1}{\\sum_{i=1}^n r^{(i)}} \\sum_{i=1}^n r^{(i)}\\cdot \\left ( {y^{(i)}} \\ln \\sigma^{(i)}+ (1- y^{(i)}) \\ln (1-\\sigma^{(i)}) \\right ) + \\frac{\\lambda}{2} \\|\\mathbf{w}\\|_2^2$$\n",
    "\n",
    "We can for example use the relative frequency of the training data to set $r^{(i)}$. Let $n^+ = \\sum_{i=1}^n y^{(i)}$ and $n^- = n - n^+$ be the number of positive and negative training instances respectively in the training data. The weights can be set as \n",
    "\n",
    "$$r^{(i)} = \\begin{cases}\\frac{n}{n^-} & y^{(i)} = 0 \\\\ \\frac{n}{n^+} & y^{(i)} =1\\end{cases}$$\n",
    "\n",
    "\n",
    "\n",
    "* derive and write down the gradient of the weighted loss w.r.t the learning parameter\n",
    "\n",
    "* implement a suitable training algorithm to learn the parameter\n",
    "\n",
    "* report the learnt parameter with $\\lambda =0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f6fbd-0103-4f4e-a803-2870aefa7708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T13:00:22.714521Z",
     "iopub.status.busy": "2025-02-13T13:00:22.714064Z",
     "iopub.status.idle": "2025-02-13T13:00:22.730587Z",
     "shell.execute_reply": "2025-02-13T13:00:22.729247Z",
     "shell.execute_reply.started": "2025-02-13T13:00:22.714474Z"
    }
   },
   "outputs": [],
   "source": [
    "## gradient expression here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f452c5-9a7c-4be1-9775-16320c4f46ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T13:00:22.732470Z",
     "iopub.status.busy": "2025-02-13T13:00:22.732024Z",
     "iopub.status.idle": "2025-02-13T13:00:22.749362Z",
     "shell.execute_reply": "2025-02-13T13:00:22.748086Z",
     "shell.execute_reply.started": "2025-02-13T13:00:22.732426Z"
    }
   },
   "outputs": [],
   "source": [
    "## Implement and run your algorithm and report your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b10cb5",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Hand in via MMS: the completed jupyter notebook. Your notebook should be reproducible. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4422044c",
   "metadata": {},
   "source": [
    "## Marking\n",
    "Your submission will be marked as a whole. \n",
    "\n",
    "* to get a grade above 7, you are expected to finish at least Task 1.1 to a good standard\n",
    "* to get a grade above 10 and up to 13, you are expected to complete Task 1.1-1.2 and Task 2.1 to a good standard\n",
    "* to get a grade above 13 and up to 17, you are expected to complete all tasks except 2.3 and 2.4 a good standard\n",
    "* to achieve a grade of 17+, you are expected to finish all tasks well\n",
    "* to get 18+, you are expected to attempt all questions flawlessly\n",
    "\n",
    "\n",
    "## Policies\n",
    "\n",
    "* See the Generic Mark Descriptors in the School Student Handbook: \n",
    "\n",
    "  [http://info.cs.st-andrews.ac.uk/student-handbook/learning-teaching/feedback.html#Mark_Descriptors](http://info.cs.st-andrews.ac.uk/student-handbook/learning-teaching/feedback.html#Mark_Descriptors)\n",
    "\n",
    "\n",
    "* The standard penalty for late submission applies (Scheme A: 1 mark per 24 hour period, or part thereof):\n",
    "  \n",
    "  [http://info.cs.st-andrews.ac.uk/student-handbook/learning-teaching/assessment.html#lateness-penalties](http://info.cs.st-andrews.ac.uk/student-handbook/learning-teaching/assessment.html#lateness-penalties)\n",
    "\n",
    "\n",
    "* The University policy on Good Academic Practice applies:\n",
    "\n",
    "  [https://www.st-andrews.ac.uk/students/rules/academicpractice/](https://www.st-andrews.ac.uk/students/rules/academicpractice/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
